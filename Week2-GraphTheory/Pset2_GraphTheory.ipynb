{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2 Problem Set: Graph Theory\n",
    "\n",
    "In this exercise we will work with real data from the C. Elegans nervous system, using data shared by the [WormAtlas](http://www.wormatlas.org/) database.  We will treat it as an undirected connectome for the purposes of this exercise.\n",
    "\n",
    "For some problems you will be provided with skeleton code - fill in the lines marked ```...``` with appropriate code to solve problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas,numpy\n",
    "import os,sys\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from utils import mk_random_graph\n",
    "\n",
    "%matplotlib inline\n",
    "# read the data from Wormatlas.org: see section 2.1 of http://www.wormatlas.org/neuronalwiring.html for details\n",
    "\n",
    "celegans_connectome=pandas.read_excel('http://www.wormatlas.org/images/NeuronConnect.xls')\n",
    "\n",
    "# set up the graph\n",
    "Gd = nx.DiGraph()\n",
    "for i in celegans_connectome.index:\n",
    "    Gd.add_edge(celegans_connectome.loc[i]['Neuron 1'],celegans_connectome.loc[i]['Neuron 2'])\n",
    "    \n",
    "Gu=Gd.to_undirected()\n",
    "\n",
    "# the graph has two connected components, so we will just keep the giant component\n",
    "components=nx.connected_component_subgraphs(Gu)\n",
    "G=next(components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:\n",
    "\n",
    "a. Plot a histogram of the degree distribution, and print out the mean and maximum degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Compute the average clustering coefficient for the connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_clustering = ...\n",
    "print(ce_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Compute the average path length for the connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_avgpathlength = ...\n",
    "print(ce_avgpathlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "\n",
    "First, use the provided code to create 100 random graphs with the same size as the C. Elegans connectome. For each graph, we compute its average clustering, average shortest path length, and maximum degree, and store those to a numpy array. (This may take a few minutes to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDED CODE\n",
    "nruns=100\n",
    "measures=['clustering','avgpathlength','maxdegree']\n",
    "results=pandas.DataFrame(numpy.zeros((nruns,len(measures))),\n",
    "                        columns=measures)\n",
    "\n",
    "for i in range(nruns):\n",
    "    G_rand = mk_random_graph(G)\n",
    "    results.iloc[i]['clustering']=nx.average_clustering(G_rand)\n",
    "    results.iloc[i]['avgpathlength']=nx.average_shortest_path_length(G_rand)\n",
    "    results.iloc[i]['maxdegree']=numpy.max([G_rand.degree[i] for i in G_rand.nodes])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.  Compute the tail probability of the observed values of cluster and path length for the C. elegans network, in comparison to the random network results.  That is, what is the probability of a value as or more extreme than the observed value wihtin the random graph distribution? You may find the function ```scipy.stats.percentileofscore()``` useful for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROVIDED CODE: \n",
    "\n",
    "p_clustering=...\n",
    "print('Observed:',ce_clustering,'Random:',results['clustering'].mean(),'P<',p_clustering)\n",
    "\n",
    "p_avgpathlength=...\n",
    "print('Observed:',ce_avgpathlength,'Random:',results['avgpathlength'].mean(),'P<',p_avgpathlength)\n",
    "\n",
    "p_maxdegree=...\n",
    "print('Observed:',numpy.max(degree_vals),'Random:',results['maxdegree'].mean(),'P<',p_maxdegree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of this analysis, do you think that the C. Elegans connectome is a \"small world\" network\"? explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3:\n",
    "\n",
    "Determine which neuron is the most important based on these four criteria:\n",
    "\n",
    "- degree centrality\n",
    "- betweenness centrality\n",
    "- closeness centrality\n",
    "- eigenvector centrality\n",
    "\n",
    "Because networkx returns a dictionary when it computes centrality measures, we have provided a utility function to return the entry with the largest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROVIDED CODE\n",
    "\n",
    "def get_max_from_dict(d):\n",
    "    \"\"\"\n",
    "    return the dict entry with the max value\n",
    "    after https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
    "    \"\"\"\n",
    "    return max(d, key=lambda key: d[key])\n",
    "\n",
    "central_nodes={}\n",
    "# compute degree centrality\n",
    "central_nodes['degree']=get_max_from_dict(...)\n",
    "# compute eigenvector centrality\n",
    "central_nodes['eigenvector']=get_max_from_dict(...)\n",
    "# compute betweenness centrality\n",
    "central_nodes['betweenness']=get_max_from_dict(...)\n",
    "# compute closeness centrality\n",
    "central_nodes['closeness']=get_max_from_dict(...)\n",
    "\n",
    "print(central_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the most central node differs between the different measures.  Given what you know about those measures, explain why this might be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
